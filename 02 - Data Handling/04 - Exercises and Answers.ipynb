{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2976fec",
   "metadata": {},
   "source": [
    "# Workbook 4 - Exercises and Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa1191",
   "metadata": {},
   "source": [
    "Before we start, let's get Colab set up for this workbook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9109c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install h5py\n",
    "%pip install lmfit\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "\n",
    "!git clone https://github.com/timsnow/advanced_sas_training_course\n",
    "%cd 'advanced_sas_training_course/02 - Data Handling'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65758f2c",
   "metadata": {},
   "source": [
    "With Colab set up, let's set up this workbook for the exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ae5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from lmfit.models import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hdf_file_path = 'data/i22-363058.h5'\n",
    "text_file_path = 'data/i22-363110.dat'\n",
    "internal_hdf_data_path = '/entry/data/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399a74e",
   "metadata": {},
   "source": [
    "Using the `with xxx as yyy:` pattern, load the data contained within the hdf and text files nominated above into the following variables:\n",
    "\n",
    " - From the .h5 file load in the `/entry/data/data` dataset as a variable called `two_d_dataset`\n",
    " - From the .dat file load in the data, using numpy, and then create both an `x_dataset` and `y_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec42451",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdf_file_path, 'r') as file_handle:\n",
    "    hdf5_dataset = file_handle[internal_hdf_data_path][()]\n",
    "    \n",
    "two_d_dataset = hdf5_dataset[0][0]\n",
    "\n",
    "#########\n",
    "\n",
    "dat_dataset = np.loadtxt(text_file_path, comments = '#', skiprows = 0, delimiter = '\\t')\n",
    "\n",
    "x_dataset = dat_dataset[:,0]\n",
    "y_dataset = dat_dataset[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72588b2",
   "metadata": {},
   "source": [
    "Using matplotlib create a basic plot of both of these datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b108f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_dataset, y_dataset)\n",
    "plt.title('SAXS Data')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Intensity (arb.)')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('$q$ (A$^{-1}$)')\n",
    "plt.plot(x_dataset, y_dataset)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.log(two_d_dataset))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047af75",
   "metadata": {},
   "source": [
    "Run the following cell to instanciate a function that will let you generate some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dacd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_gaussian_function(x_axis, a, b, c, noise_factor):\n",
    "    length_of_x_axis = len(x_axis)\n",
    "    noise_to_add = (np.random.randn(length_of_x_axis) * noise_factor) / (1 / x_axis)\n",
    "    return (a * np.exp(-((x_axis - b)**2 / (2 * c**2)))) + noise_to_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8259998c",
   "metadata": {},
   "source": [
    "Using `numpy` generate a dataset called `x_axis` and then use the function above on that dataset to generate a `y_axis` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.linspace(start = 0, stop = 100, num = 1000)\n",
    "y_axis = noisy_gaussian_function(x_axis, 1, 50, 4, 0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea708e89",
   "metadata": {},
   "source": [
    "Use the following cell to plot this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_axis, y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca7222",
   "metadata": {},
   "source": [
    "Using `lmfit` and the `GaussianModel()` class, fit this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_model = GaussianModel()\n",
    "initial_guesses = gaussian_model.guess(data = y_axis, x = x_axis)\n",
    "gaussian_fit = gaussian_model.fit(data = y_axis, params = initial_guesses, x = x_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_fit.plot_fit()\n",
    "plt.show()\n",
    "print(gaussian_fit.fit_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a763889",
   "metadata": {},
   "source": [
    "###Â Extra credit - for after the training course\n",
    "\n",
    "Using the `lmfit` webpage on multiple peak fitting, attempt a fit on the following dataset, which is a simulation of an actual SAS dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2cf235",
   "metadata": {},
   "source": [
    "The following code snippet will be of use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fe12c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gaussian_function(x_axis, a, b, c):\n",
    "    return a * np.exp(-((x_axis - b)**2 / (2 * c**2)))\n",
    "\n",
    "noise_factor = 5000\n",
    "peak_height = 10\n",
    "intensity_value = 1\n",
    "q_data = np.linspace(2, 200, 198)\n",
    "q_data /= 1000\n",
    "i_data = intensity_value / q_data**4\n",
    "\n",
    "peak_one =   gaussian_function(q_data, (i_data[38]  * peak_height), 0.04, 0.001)\n",
    "peak_two =   gaussian_function(q_data, (i_data[78]  * peak_height), 0.08, 0.001)\n",
    "peak_three = gaussian_function(q_data, (i_data[118] * peak_height), 0.12, 0.001)\n",
    "peak_four =  gaussian_function(q_data, (i_data[158] * peak_height), 0.16, 0.001)\n",
    "\n",
    "i_data += peak_one + peak_two + peak_three + peak_four\n",
    "di_data = (np.random.rand(len(i_data)) * noise_factor) + np.sqrt(i_data)\n",
    "\n",
    "plt.fill_between(q_data, i_data - di_data, i_data + di_data, color='gray', alpha=0.5)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ff1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss1 = GaussianModel(prefix='g1_')\n",
    "gauss2 = GaussianModel(prefix='g2_')\n",
    "gauss3 = GaussianModel(prefix='g3_')\n",
    "gauss4 = GaussianModel(prefix='g4_')\n",
    "background = ExpressionModel('bgval / x**4')\n",
    "overall_model = gauss1 + gauss2 + gauss3 + gauss4 + background\n",
    "\n",
    "overall_parameters = gauss1.make_params()\n",
    "overall_parameters.update(gauss2.make_params())\n",
    "overall_parameters.update(gauss3.make_params())\n",
    "overall_parameters.update(gauss4.make_params())\n",
    "overall_parameters.update(background.make_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0624d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in overall_parameters:\n",
    "    if 'amplitude' in key:\n",
    "        overall_parameters[key].value = 10\n",
    "        overall_parameters[key].min = 0\n",
    "        overall_parameters[key].max = 1e10  \n",
    "    elif 'center' in key:\n",
    "        overall_parameters[key].min = 0.002\n",
    "        overall_parameters[key].max = 0.2\n",
    "    elif 'fwhm' in key:\n",
    "        overall_parameters[key].value = 0.002\n",
    "        overall_parameters[key].min = 0\n",
    "        overall_parameters[key].max = 0.1\n",
    "    elif 'height' in key:\n",
    "        overall_parameters[key].value = 20\n",
    "        overall_parameters[key].min = 0\n",
    "        overall_parameters[key].max = 1e10      \n",
    "    elif 'sigma' in key:\n",
    "        overall_parameters[key].value = 0.005\n",
    "        overall_parameters[key].min = 0\n",
    "        overall_parameters[key].max = 0.1\n",
    "\n",
    "overall_parameters['g1_center'].value = 0.05\n",
    "overall_parameters['g2_center'].value = 0.07\n",
    "overall_parameters['g3_center'].value = 0.13\n",
    "overall_parameters['g4_center'].value = 0.15\n",
    "overall_parameters['bgval'].value = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_fit = overall_model.fit(data = i_data, params = overall_parameters, x = q_data)\n",
    "overall_fit.plot_fit()\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "print(overall_fit.fit_report())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
