{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed2c849",
   "metadata": {},
   "source": [
    "# Workbook 1 - Data Ingest & Plotting\n",
    "\n",
    "Whatever you're going to do you're going to want to get data into your program and do something with it, perhaps even writing it back to disk afterwards!\n",
    "\n",
    "This workbook will look at three common ways to ingest data from a file.\n",
    "\n",
    "However, just before we start, for Google Colab, we need to set up a couple of things. On your computer you would have all the packages and data you need installed beforehand and, crucially, they would then stay on your machine. However, Colab is 'in the cloud' so we need to install things (or at least make sure they're accessible) in advance of running them. To save time later we shall install all the packages needed for this workbook and the data required to go through this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69729744",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "\n",
    "!git clone https://github.com/timsnow/advanced_sas_training_course\n",
    "%cd 'advanced_sas_training_course/02 - Data Handling'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33324f86",
   "metadata": {},
   "source": [
    "## HDF Files\n",
    "\n",
    "One of the most common file formats at Diamond is the NeXus, or HDF, file. These files are binary files which store data within them a lot like files are stored on a computer disc; by which I mean they have an internal structure.\n",
    "\n",
    "![NeXus File Structure](images/01.png)\n",
    "\n",
    "The screenshot above shows the typical internal structure of an [NXsas](https://manual.nexusformat.org/classes/applications/NXsas.html) compliant NeXus file. As you can see there's a lot in there, however, what would probably be of most interest would be the `data` array which has been highlighted.\n",
    "\n",
    "To keep things a bit simplier, for this example we are going to work with a stripped down detector dataset where the data can be found under the path '/entry/data/data'\n",
    "\n",
    "Before we get going we will need to import a new module `h5py`.\n",
    "\n",
    "`h5py` is the 'official' Python package that handles HDF5 files, therefore if we are going to work with NeXus/HDF5 files we will need this package - documentation on this package and it's functions can be found here [HDF5 for Python](https://docs.h5py.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc97ae81",
   "metadata": {},
   "source": [
    "With our packages loaded we're now able to declare a couple of reference variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/i22-363058.h5'\n",
    "internal_data_path = '/entry/data/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9710aeb",
   "metadata": {},
   "source": [
    "Whilst we could 'hard code' these into the following part of the script, having them as standalone strings allows, at a glance, to see a number of pertinent variables without having to dig through the code line-by-line; it also allows for easier code *refactoring* in the future.\n",
    "\n",
    "*Refactoring* is \"a systematic process of improving code without creating new functionality.\"\n",
    "\n",
    "If we keep the `file_path` and `internal_data_path` as variables we can easily convert the next code fragment into a function without having to perform extensive code re-writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593455cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle = h5py.File(file_path, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c3a9b",
   "metadata": {},
   "source": [
    "In the above we are asking h5py to open the file, found at `file_path` in the 'mode' `'r'`. \n",
    "\n",
    "A file mode lets Python know a little about what you're expecting to do with a file; there are 5 potential file 'modes' for `h5py`:\n",
    "\n",
    " - r\tReadonly, file must exist (default)\n",
    " - r+\tRead/write, file must exist\n",
    " - w\tCreate file, truncate if exists\n",
    " - w- or x\tCreate file, fail if exists\n",
    " - a\tRead/write if exists, create otherwise\n",
    " \n",
    " Treat these with care and caution - opening a file with the wrong mode can end up over-writing the file resulting in data loss (permanent data loss if you don't have a backup!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = file_handle[internal_data_path][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd87b9",
   "metadata": {},
   "source": [
    "Now that we have the file open, we are able to navigate to the data location in the file and ask `h5py` to return this as a `numpy` array using the `[()]` operator. \n",
    "\n",
    "Historically, this was achieved *via* use of `file_handle[internal_data_path].value()`, however, this is in the process of being depricated (phased out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176cf9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a5bb9",
   "metadata": {},
   "source": [
    "Now that we're done with the file, it is good practice to 'close' the file so as not to tie up resorces (or accidentally do something silly!), this is achieved using the `close()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef0b76",
   "metadata": {},
   "source": [
    "Interesting... seems to be a lot of opening and closing square brackets on this dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512eec6",
   "metadata": {},
   "source": [
    "Having a quick look at the dataset using `dir()` reveals that we've got a lot of functions here, however, for now, we shall use shape to find out what 'shape' our data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cfd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f001d39",
   "metadata": {},
   "source": [
    "Ah, it seems that this dataset is a single frame of data that was acquired at a single position and therefore has the shape \\[1, 1, detY, detX\\] - if we address just the first element of this dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e55f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455accb3",
   "metadata": {},
   "source": [
    "Looks a bit more like one might expect now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba12ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe = dataset[0][0]\n",
    "final_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f17892",
   "metadata": {},
   "source": [
    "Chaining all of this together we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ad795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "file_path = 'data/i22-363058.h5'\n",
    "internal_data_path = '/entry/data/data'\n",
    "\n",
    "file_handle = h5py.File(file_path, 'r')\n",
    "dataset = file_handle[internal_data_path][()]\n",
    "file_handle.close()\n",
    "\n",
    "final_dataframe = dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e8b29",
   "metadata": {},
   "source": [
    "As ever, this is one way to acheive this. The above example will work for any file and any purpose, however, it's a blunt tool to get the job done - a more 'Pythonic' way of achieving this would be to use the `with` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee25434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "file_path = 'data/i22-363058.h5'\n",
    "internal_data_path = '/entry/data/data'\n",
    "\n",
    "with h5py.File(file_path, \"r\") as file_handle:\n",
    "    dataset = file_handle[internal_data_path][()]\n",
    "    \n",
    "final_dataframe = dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366f1c7",
   "metadata": {},
   "source": [
    "At first glance it would seem that all this has done is to remove the `close()` statement, however, using this mechanism provides a richer set of *exceptions* allowing you to debug your code more effectively.\n",
    "\n",
    "With some data 'in hand' let's look at another couple of ways of extracting data from files before moving on to plotting this data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d43e0d",
   "metadata": {},
   "source": [
    "## Delimited Text Files\n",
    "\n",
    "Be they tabs, commas, spaces, a lot of data files are simply text that makes use of a `delimiter`. As this is such a common way of persisting (saving) data to disk there are a number of functions in a number of modules that will handle this for you. In this example we're going to use the `numpy` module.\n",
    "\n",
    "`numpy` is probably one, if not the most, imported package in Python. If you are going to do *anything* scientific with numbers in Python you'll want `numpy` by your side. The reference manual for `numpy` can be found here [NumPy Reference](https://numpy.org/doc/stable/reference/index.html), however, you'd probably find using Google and a well crafted search a better navigator of the `numpy` manual as it is **extensive**.\n",
    "\n",
    "![Numpy](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41586-020-2649-2/MediaObjects/41586_2020_2649_Fig2_HTML.png)\n",
    "<div align=\"center\"><br />\n",
    "NumPy is the base of the scientific Python ecosystem - <a href=\"https://doi.org/10.1038/s41586-020-2649-2\">Array Programming with NumPy</a> - CC-BY-4.0\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0805c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # As is convention\n",
    "\n",
    "data = np.loadtxt('data/i22-363110.dat', comments = '#', skiprows = 0, delimiter = '\\t')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22006e18",
   "metadata": {},
   "source": [
    "Two things come up here, the use of `#`'s in Python programs and `np.loadtxt`\n",
    "\n",
    "If you see a line starting with a `#`, or some text after a `#` in a line these are *comments*. Python ignores *anything* after a `#` character on that line. If you require to make multi-line comments it is *suggested* that you use multiple `#` symbols on many lines rather than using the multi-line 'docstring' keyword.\n",
    "\n",
    "The exact reasoning for this is beyond the scope of this exercise but more information can be found here: [PEP 8 -- Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008/#block-comments).\n",
    "\n",
    "Next up, `np.loadtxt`, with this function we have specified:\n",
    "\n",
    " - a path to the file\n",
    " - that any lines starting with `#`'s to be ignored (typically headers)\n",
    " - that we intend to load the whole data part of the file, not skipping any rows in the file\n",
    " - that the delimiter is a tab character (`\\t`\\*)\n",
    "\n",
    "Complete documentation on `np.loadtxt()` can be found here [numpy.loadtxt](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html)\n",
    "\n",
    "\\* - A full list of so-called 'string literals' can be found here [Lexical analysis](https://docs.python.org/3/reference/lexical_analysis.html) under section 2.4.1.\n",
    "\n",
    "With this dataset in hand we can use 'fancy' indexing to get out the first two columns of the data into two separate arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb36047",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data[:,0]\n",
    "y_data = data[:,1]\n",
    "dy_data = data[:,2]\n",
    "\n",
    "print(x_data[0:10])\n",
    "print('')\n",
    "print(y_data[0:10])\n",
    "print('')\n",
    "print(dy_data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ee147",
   "metadata": {},
   "source": [
    "With some data 'in hand' let's look at one final way to extracting data from files before moving on to plotting this data.\n",
    "\n",
    "\n",
    "### Further reading\n",
    "\n",
    "`numpy` also has a `fromfile()` function for extracting out binary data from a file, as opposed to text data: [numpy.fromfile](https://numpy.org/doc/stable/reference/generated/numpy.fromfile.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5eeadf",
   "metadata": {},
   "source": [
    "## Custom File Loading\n",
    "\n",
    "As covered yesterday, it is *highly* recommend using an existing package in order to load data from a file. As such this section will be more of a refernce 'how-to' rather than a fully worked example.\n",
    "\n",
    "Firstly we must understand what format the data is in, is it text or binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c86c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle = open('path/to/file.aaa', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68036a4",
   "metadata": {},
   "source": [
    "Using this form of the Python `open` keyword will, by default, attempt to open a file for reading text. This plays well with a number of file formats, however, creates headaches for pure binary files. In the case of binary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65efdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle = open('path/to/file.aaa', 'rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d50f1",
   "metadata": {},
   "source": [
    "The `rb` file mode will load the file as pure binary meaning that you won't have to cast a potentially very long string into a binary format before dealing with the binary data.\n",
    "\n",
    "When directly handling files the following functions are of great use:\n",
    "\n",
    " - `read()` - Reads a number of bytes from a file\n",
    " - `readline()` - Reads a line of a file\n",
    " - `readlines()` - Reads *n* lines of a file or, if no number is specified, the whole file into a list\n",
    " - `seek()` - Go to byte *n* of a file, or the beginning of the file if no number is specified\n",
    " \n",
    "Once you have loaded data into your program there are a number programming patterns that will help you 'unpack' your data into something more 'useful' downstream.\n",
    "\n",
    "By far the most straightforward is `numpy`'s `frombuffer` function. This behaves exactly the same as `np.fromfile` but expects the binary data to be coming from a loaded variable rather than a file. To load in a stream of integer binary data you'd simply need to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('path/to/file.aaa', 'rb') as file_handle:\n",
    "    binary_data = file_handle.read()\n",
    "\n",
    "data = np.frombuffer(binary_data, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394dc05b",
   "metadata": {},
   "source": [
    "It is worth noting that the `dtype` keyword refers to the `d`ata `type` and a full list of these can be found here: [Data type objects (dtype)](https://numpy.org/doc/stable/reference/arrays.dtypes.html)\n",
    "\n",
    "Reading in text data usually makes use of Python's `strip` and `split` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_string = '...........A long string, full of lots of characters, that we can play with...........'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b767bd4b",
   "metadata": {},
   "source": [
    "The `strip()` function simply removes all occurances of a particular character at the beginning or end of a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b264c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_string = text_string.strip('.')\n",
    "print(stripped_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa35df5",
   "metadata": {},
   "source": [
    "From here we might want to break this line down into parts using a delimiter such as the **mighty comma*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a974234",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = stripped_string.split(',')\n",
    "print(string_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9cfb1a",
   "metadata": {},
   "source": [
    "As you can see, this starts to encroach on `numpy`s `fromtxt` function which would be the recommeded route to pursue here.\n",
    "\n",
    "Finally, when you have loaded data into a program it is likely that you will have loaded it in as a long, one dimensional, array. Naturally, if you are trying to recover a 2D image this is less than optimal - here `numpy`s `reshape` function comes into play (documentation: [numpy.reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)). This function allows you to provide an input array, the shape you wish for it to have and will return the array 'reshaped' ready for downstream use.\n",
    "\n",
    "For completeness, it is probably also worth highlighting a number of other useful array manipulation functions within `numpy`, namely:\n",
    "\n",
    " - `transpose` - reverse or permute the axes of an array (documentation: [numpy.transpose](https://numpy.org/doc/stable/reference/generated/numpy.transpose.html))\n",
    " - `rot90` - rotate an array by 90 degrees in the plane specified by axes (documentation: [numpy.rot90](https://numpy.org/doc/stable/reference/generated/numpy.rot90.html))\n",
    " - `flip` - reverse the order of elements in an array along the given axis (documentation: [numpy.flip](https://numpy.org/doc/stable/reference/generated/numpy.flip.html))\n",
    " - `fliplr` - flip array in the left/right direction (documentation: [numpy.fliplr](https://numpy.org/doc/stable/reference/generated/numpy.fliplr.html))\n",
    " - `flipud` - flip array in the up/down direction (documentation: [numpy.flipud](https://numpy.org/doc/stable/reference/generated/numpy.flipud.html))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde65ca",
   "metadata": {},
   "source": [
    "## Plotting Data!\n",
    "\n",
    "Right, we've got some data: `final_dataframe` and `x_data`/`y_data`: let's see what we've loaded in!\n",
    "\n",
    "To do this we're going to use a module called `matplotlib` so called because it was designed to bring all of MATLABs plotting library to Python.\n",
    "\n",
    "It is deceptively easy to start using but has the appeal of drawing you ever deeper in by offering increasingly beautiful plots...\n",
    "\n",
    "### 1D Plots\n",
    "\n",
    "To start with, let's visualise the `x_data`/`y_data` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # As is the convention\n",
    "\n",
    "plt.plot(x_data, y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5875d7",
   "metadata": {},
   "source": [
    "Excellent!\n",
    "\n",
    "Hopefully the syntax isn't too taxing, we simply specify that we'd like to plot dataset `a` against `b` and ask for that plot to be shown (we might want multiple lines on a graph).\n",
    "\n",
    "Except... SAXS data is usually plotted on a log scale!\n",
    "\n",
    "OK, round two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data, y_data)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536a486",
   "metadata": {},
   "source": [
    "Excellent!\n",
    "\n",
    "Just a couple of new functions and we've gone from a linear plot to a log plot, except... axis labels anyone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbfd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data, y_data)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Intensity (arb.)')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('$q$ (A$^{-1}$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176fbb41",
   "metadata": {},
   "source": [
    "Excellent!\n",
    "\n",
    "With a couple more functions (and some additions from the [Writing mathematical expressions](https://matplotlib.org/stable/tutorials/text/mathtext.html) section of the MPL documentation) we've got a plot, on a log scale, with axis labels, except... a plot title anyone? Defined plot limits? Uncertainties on the datapoints?\n",
    "\n",
    "Everything *is* possible but things quickly start sprawling out of control. The MPL documentation has wonderful pages of [graphical examples](https://matplotlib.org/stable/gallery/index.html) and through [reference guide](https://matplotlib.org/stable/api/pyplot_summary.html) for every function, however these [cheat sheets](https://github.com/matplotlib/cheatsheets#cheatsheets) are the ultimate - at a glance - reference guide.\n",
    "\n",
    "The beginner's cheatsheet is probably enough to be going on for now:\n",
    "\n",
    "![Beginner's cheatsheet](https://github.com/matplotlib/cheatsheets/raw/master/handout-beginner.png)\n",
    "\n",
    "\n",
    "With all of this in mind - we can finally arrive at a graph like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data, y_data)\n",
    "plt.title('SAXS Data')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Intensity (arb.)')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('$q$ (A$^{-1}$)')\n",
    "plt.xlim(0.002, 0.2)\n",
    "plt.fill_between(x_data, y_data - dy_data, y_data + dy_data, color='gray', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee6431d",
   "metadata": {},
   "source": [
    "And this marks only the start of the rabbit hole one can go down...\n",
    "\n",
    "Remember, easy to pick up but difficult to put down!\n",
    "\n",
    "Rather than go through all of the different functions in depth the above serves as a minimum working example of the kinds of functions that you might wish to use when constructing a line plot.\n",
    "\n",
    "### 2D Plots\n",
    "\n",
    "In a similar vein to 1D plotting - deceptively simple using `plt.imshow()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(final_dataframe)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c600f7",
   "metadata": {},
   "source": [
    "However, as this is SAXS data it would be better if the intensities were log scaled, which we can do with `np.log()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a02e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(final_dataframe))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df415e76",
   "metadata": {},
   "source": [
    "Now, there's a few error messages here as taking the logarithm of zero, or negative numbers, is somewhat mathematically frowned upon. However, `numpy` is forgiving and moves on complaining into the ether about the numpties that are using it.\n",
    "\n",
    "Naturally, most of the above methods *e.g.* `x/ylabel`, `x/ylim`, `title`, etc. are all still valid for this form of plotting and exploration is encouraged!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d128a",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    " - h5py - [HDF5 for Python](https://docs.h5py.org)\n",
    " - numpy - [NumPy Documentation](https://numpy.org/doc/)\n",
    " - matplotlib - [Overview - Matplotlib](https://matplotlib.org/stable/contents.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
